{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sklearn for Windows devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sklearn for MacOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>00017</th>\n",
       "      <th>0003</th>\n",
       "      <th>0004</th>\n",
       "      <th>0005</th>\n",
       "      <th>001</th>\n",
       "      <th>0021</th>\n",
       "      <th>003</th>\n",
       "      <th>...</th>\n",
       "      <th>zwf1</th>\n",
       "      <th>zwitterionic</th>\n",
       "      <th>zygomycete</th>\n",
       "      <th>zygomycetes</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymogen</th>\n",
       "      <th>zymogens</th>\n",
       "      <th>zymogram</th>\n",
       "      <th>zymography</th>\n",
       "      <th>zymomonas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0001  00017  0003  0004  0005  001  0021  003  ...  zwf1  \\\n",
       "0   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "1   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "2   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "3   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "4   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "\n",
       "   zwitterionic  zygomycete  zygomycetes  zygotic  zymogen  zymogens  \\\n",
       "0             0           0            0        0        0         0   \n",
       "1             0           0            0        0        0         0   \n",
       "2             0           0            0        0        0         0   \n",
       "3             0           0            0        0        0         0   \n",
       "4             0           0            0        0        0         0   \n",
       "\n",
       "   zymogram  zymography  zymomonas  \n",
       "0         0           0          0  \n",
       "1         0           0          0  \n",
       "2         0           0          0  \n",
       "3         0           0          0  \n",
       "4         0           0          0  \n",
       "\n",
       "[5 rows x 26179 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv('trg.csv')\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(data.abstract)\n",
    "\n",
    "data = data.rename(columns={'class': 'class_label'})\n",
    "X = data.drop('class_label', axis=1)\n",
    "y = data['class_label']\n",
    "data  = pd.DataFrame(data= matrix.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['abstract'], y, test_size=0.1, random_state=42)\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "        self.class_priors = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.vocab = set()\n",
    "        for cls in self.classes:\n",
    "            self.class_counts[cls] = sum(1 for label in y if label == cls)\n",
    "        for abstract, label in zip(X, y):\n",
    "            for word in set(abstract.split()):\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        total_docs = len(X)\n",
    "        self.class_priors = {cls: self.class_counts[cls] / total_docs for cls in self.classes}\n",
    "\n",
    "    def predict(self, documents):\n",
    "        predictions = []\n",
    "        for document in documents:\n",
    "            posterior_probs = {cls: np.log(self.class_priors[cls]) for cls in self.classes}\n",
    "            document_words = document.split()\n",
    "            word_counts = {word: document_words.count(word) for word in set(document_words)}\n",
    "            for word, count in word_counts.items():\n",
    "                for cls in self.classes:\n",
    "                    word_count_in_class = self.word_counts[cls].get(word, 0)\n",
    "                    total_words_in_class = sum(self.word_counts[cls].values())\n",
    "                    conditional_prob = (word_count_in_class + 1) / (total_words_in_class + self.vocab_size)\n",
    "                    posterior_probs[cls] += count * np.log(conditional_prob)\n",
    "            predicted_class = max(posterior_probs, key=posterior_probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions\n",
    "\n",
    "nb_clf = NaiveBayes()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved with extra-preprocessing & Evaluating model's performance using k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n",
      "5-fold cross-validation accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['abstract'], y, test_size=0.01, random_state=42)\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "        self.class_priors = {}\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        words = text.split()\n",
    "        processed_words = []\n",
    "        skip_next = False\n",
    "        skip_next_next = False\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if skip_next:\n",
    "                skip_next = False\n",
    "                if skip_next_next:\n",
    "                    skip_next = True\n",
    "                    skip_next_next = False\n",
    "                continue\n",
    "\n",
    "            if word == \"homo\" and i + 1 < len(words) and words[i + 1] == \"sapiens\":\n",
    "                processed_words.append(\"homo-sapiens\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "\n",
    "            if word == \"escherichia\" and i + 1 < len(words) and words[i + 1] == \"coli\":\n",
    "                processed_words.append(\"escherichia-coli\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "\n",
    "            if word == \"human\" and i + 2 < len(words) and words[i + 1] == \"immunodeficiency\" and words[i + 2] == \"virus\":\n",
    "                processed_words.append(\"human-immunodeficiency-virus\")\n",
    "                skip_next = True\n",
    "                skip_next_next = True\n",
    "\n",
    "            if word not in ENGLISH_STOP_WORDS:\n",
    "                processed_words.append(word)\n",
    "\n",
    "        return \" \".join(processed_words)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.vocab = set()\n",
    "\n",
    "        for cls in self.classes:\n",
    "            self.class_counts[cls] = sum(1 for label in y if label == cls)\n",
    "\n",
    "        for abstract, label in zip(X, y):\n",
    "            abstract = self.preprocess(abstract)\n",
    "            for word in set(abstract.split()):\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        total_docs = len(X)\n",
    "        self.class_priors = {cls: self.class_counts[cls] / total_docs for cls in self.classes}\n",
    "\n",
    "    def predict(self, documents):\n",
    "        predictions = []\n",
    "        for document in documents:\n",
    "            document = self.preprocess(document)\n",
    "            posterior_probs = {cls: np.log(self.class_priors[cls]) for cls in self.classes}\n",
    "            document_words = document.split()\n",
    "            word_counts = {word: document_words.count(word) for word in set(document_words)}\n",
    "\n",
    "            for word, count in word_counts.items():\n",
    "                for cls in self.classes:\n",
    "                    word_count_in_class = self.word_counts[cls].get(word, 0)\n",
    "                    total_words_in_class = sum(self.word_counts[cls].values())\n",
    "                    conditional_prob = (word_count_in_class + self.alpha) / (total_words_in_class + self.alpha * self.vocab_size)\n",
    "                    posterior_probs[cls] += count * np.log(conditional_prob)\n",
    "\n",
    "            predicted_class = max(posterior_probs, key=posterior_probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "nb_clf = NaiveBayes(alpha=0.5)\n",
    "nb_clf.fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "for train_index, test_index in kf.split(X['abstract']):\n",
    "    X_train, X_test = X['abstract'][train_index], X['abstract'][test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    nb_clf.fit(X_train, y_train)\n",
    "    y_pred = nb_clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f\"5-fold cross-validation accuracy: {np.mean(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tst.csv predictions for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tst.csv')\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(data.abstract)\n",
    "X = data.drop('id', axis=1)\n",
    "\n",
    "y_pred = nb_clf.predict(X['abstract'])\n",
    "\n",
    "df_predictions = pd.DataFrame({'id': range(1, len(y_pred) + 1), 'class': y_pred})\n",
    "df_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain and motivate the chosen representation & data preprocessing,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the idea behind the model improvements and their implementation (including the implementation of the standard Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the evaluation procedure (e.g., cross-validation or training/validation split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include and explain the training/validation results for the standard and improved Naive Bayes model. You can summarize results using tables (or plots), but all results have to be explained descriptively as well. be written in plain English and should not be longer than two A4 pages (export the notebook as pdf to see if the report section fits in two pages)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
