{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sklearn for Windows devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sklearn for MacOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -U scikit-learn\n",
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>00017</th>\n",
       "      <th>0003</th>\n",
       "      <th>0004</th>\n",
       "      <th>0005</th>\n",
       "      <th>001</th>\n",
       "      <th>0021</th>\n",
       "      <th>003</th>\n",
       "      <th>...</th>\n",
       "      <th>zwf1</th>\n",
       "      <th>zwitterionic</th>\n",
       "      <th>zygomycete</th>\n",
       "      <th>zygomycetes</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymogen</th>\n",
       "      <th>zymogens</th>\n",
       "      <th>zymogram</th>\n",
       "      <th>zymography</th>\n",
       "      <th>zymomonas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0001  00017  0003  0004  0005  001  0021  003  ...  zwf1  \\\n",
       "0   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "1   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "2   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "3   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "4   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "\n",
       "   zwitterionic  zygomycete  zygomycetes  zygotic  zymogen  zymogens  \\\n",
       "0             0           0            0        0        0         0   \n",
       "1             0           0            0        0        0         0   \n",
       "2             0           0            0        0        0         0   \n",
       "3             0           0            0        0        0         0   \n",
       "4             0           0            0        0        0         0   \n",
       "\n",
       "   zymogram  zymography  zymomonas  \n",
       "0         0           0          0  \n",
       "1         0           0          0  \n",
       "2         0           0          0  \n",
       "3         0           0          0  \n",
       "4         0           0          0  \n",
       "\n",
       "[5 rows x 26179 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv('trg.csv')\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(data.abstract)\n",
    "\n",
    "data = data.rename(columns={'class': 'class_label'})\n",
    "X = data.drop('class_label', axis=1)\n",
    "y = data['class_label']\n",
    "data  = pd.DataFrame(data= matrix.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standard Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 59\u001b[0m\n\u001b[1;32m     56\u001b[0m y_train, y_test \u001b[38;5;241m=\u001b[39m y[train_index], y[test_index]\n\u001b[1;32m     58\u001b[0m nb_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m---> 59\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnb_clf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     62\u001b[0m accuracies\u001b[38;5;241m.\u001b[39mappend(accuracy)\n",
      "Cell \u001b[0;32mIn[27], line 38\u001b[0m, in \u001b[0;36mNaiveBayes.predict\u001b[0;34m(self, documents)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses:\n\u001b[1;32m     37\u001b[0m     word_count_in_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mword_counts[\u001b[38;5;28mcls\u001b[39m]\u001b[38;5;241m.\u001b[39mget(word, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m     total_words_in_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_counts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     conditional_prob \u001b[38;5;241m=\u001b[39m (word_count_in_class \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m (total_words_in_class \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab_size)\n\u001b[1;32m     40\u001b[0m     posterior_probs[\u001b[38;5;28mcls\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(conditional_prob)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['abstract'], y, test_size=0.1, random_state=42)\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "        self.class_priors = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.vocab = set()\n",
    "        for cls in self.classes:\n",
    "            self.class_counts[cls] = sum(1 for label in y if label == cls)\n",
    "        for abstract, label in zip(X, y):\n",
    "            for word in set(abstract.split()):\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        total_docs = len(X)\n",
    "        self.class_priors = {cls: self.class_counts[cls] / total_docs for cls in self.classes}\n",
    "\n",
    "    def predict(self, documents):\n",
    "        predictions = []\n",
    "        for document in documents:\n",
    "            posterior_probs = {cls: np.log(self.class_priors[cls]) for cls in self.classes}\n",
    "            document_words = document.split()\n",
    "            word_counts = {word: document_words.count(word) for word in set(document_words)}\n",
    "            for word, count in word_counts.items():\n",
    "                for cls in self.classes:\n",
    "                    word_count_in_class = self.word_counts[cls].get(word, 0)\n",
    "                    total_words_in_class = sum(self.word_counts[cls].values())\n",
    "                    conditional_prob = (word_count_in_class + 1) / (total_words_in_class + self.vocab_size)\n",
    "                    posterior_probs[cls] += count * np.log(conditional_prob)\n",
    "            predicted_class = max(posterior_probs, key=posterior_probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions\n",
    "    \n",
    "kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "accuracies = []\n",
    "\n",
    "nb_clf = NaiveBayes()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "for train_index, test_index in kf.split(X['abstract']):\n",
    "    X_train, X_test = X['abstract'][train_index], X['abstract'][test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    nb_clf.fit(X_train, y_train)\n",
    "    y_pred = nb_clf.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(\"5-fold list of accuracies:\",accuracies)\n",
    "print(f\"5-fold cross-validation mean accuracy: {np.mean(accuracies):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Naive Bayes model with extra-preprocessing (stopwords, use of n-grams, stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidParameterError",
     "evalue": "The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got 0.0 instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidParameterError\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ENGLISH_STOP_WORDS\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnltk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstem\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PorterStemmer\n\u001b[0;32m----> 9\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mabstract\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mNaiveBayes\u001b[39;00m:\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, use_bigrams\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, stemming\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:203\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m to_ignore \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcls\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    201\u001b[0m params \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m params\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m to_ignore}\n\u001b[0;32m--> 203\u001b[0m \u001b[43mvalidate_parameter_constraints\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparameter_constraints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaller_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__qualname__\u001b[39;49m\n\u001b[1;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:95\u001b[0m, in \u001b[0;36mvalidate_parameter_constraints\u001b[0;34m(parameter_constraints, params, caller_name)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     90\u001b[0m     constraints_str \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[38;5;28mstr\u001b[39m(c)\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39mconstraints[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m InvalidParameterError(\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_name\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m parameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcaller_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconstraints_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam_val\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     98\u001b[0m )\n",
      "\u001b[0;31mInvalidParameterError\u001b[0m: The 'test_size' parameter of train_test_split must be a float in the range (0.0, 1.0), an int in the range [1, inf) or None. Got 0.0 instead."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['abstract'], y, test_size=0.1, random_state=42)\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, alpha=1.0, use_bigrams=False, stemming=False):\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "        self.class_priors = {}\n",
    "        self.alpha = alpha\n",
    "        self.use_bigrams = use_bigrams\n",
    "        self.stemming = stemming\n",
    "        if self.stemming:\n",
    "            self.stemmer = PorterStemmer()\n",
    "            \n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"alpha\": self.alpha,\n",
    "            \"use_bigrams\": self.use_bigrams,\n",
    "            \"stemming\": self.stemming,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        words = text.split()\n",
    "        processed_words = []\n",
    "        skip_next = False\n",
    "        skip_next_next = False\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if skip_next:\n",
    "                skip_next = False\n",
    "                if skip_next_next:\n",
    "                    skip_next = True\n",
    "                    skip_next_next = False\n",
    "                continue\n",
    "\n",
    "            if word == \"homo\" and i + 1 < len(words) and words[i + 1] == \"sapiens\":\n",
    "                processed_words.append(\"homo-sapiens\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "\n",
    "            if word == \"escherichia\" and i + 1 < len(words) and words[i + 1] == \"coli\":\n",
    "                processed_words.append(\"escherichia-coli\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "\n",
    "            if word == \"human\" and i + 2 < len(words) and words[i + 1] == \"immunodeficiency\" and words[i + 2] == \"virus\":\n",
    "                processed_words.append(\"human-immunodeficiency-virus\")\n",
    "                skip_next = True\n",
    "                skip_next_next = True\n",
    "                continue\n",
    "\n",
    "            if self.stemming:\n",
    "                word = self.stemmer.stem(word)\n",
    "\n",
    "            if word not in ENGLISH_STOP_WORDS:\n",
    "                processed_words.append(word)\n",
    "\n",
    "        if self.use_bigrams:\n",
    "            bigrams = [f\"{processed_words[i]}_{processed_words[i+1]}\" for i in range(len(processed_words)-1)]\n",
    "            processed_words.extend(bigrams)\n",
    "\n",
    "        return \" \".join(processed_words)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.vocab = set()\n",
    "\n",
    "        for cls in self.classes:\n",
    "            self.class_counts[cls] = sum(1 for label in y if label == cls)\n",
    "\n",
    "        for abstract, label in zip(X, y):\n",
    "            abstract = self.preprocess(abstract)\n",
    "            for word in set(abstract.split()):\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        total_docs = len(X)\n",
    "        self.class_priors = {cls: self.class_counts[cls] / total_docs for cls in self.classes}\n",
    "\n",
    "    def predict(self, documents):\n",
    "        predictions = []\n",
    "        for document in documents:\n",
    "            document = self.preprocess(document)\n",
    "            posterior_probs = {cls: np.log(self.class_priors[cls]) for cls in self.classes}\n",
    "            document_words = document.split()\n",
    "            word_counts = {word: document_words.count(word) for word in set(document_words)}\n",
    "\n",
    "            for word, count in word_counts.items():\n",
    "                for cls in self.classes:\n",
    "                    word_count_in_class = self.word_counts[cls].get(word, 0)\n",
    "                    total_words_in_class = sum(self.word_counts[cls].values())\n",
    "                    conditional_prob = (word_count_in_class + self.alpha) / (total_words_in_class + self.alpha * self.vocab_size)\n",
    "                    posterior_probs[cls] += count * np.log(conditional_prob)\n",
    "\n",
    "            predicted_class = max(posterior_probs, key=posterior_probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "# accuracies = []\n",
    "\n",
    "nb_clf = NaiveBayes(alpha=0.5, use_bigrams=True, stemming=True)\n",
    "nb_clf.fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# for train_index, test_index in kf.split(X['abstract']):\n",
    "#     X_train, X_test = X['abstract'][train_index], X['abstract'][test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#     nb_clf.fit(X_train, y_train)\n",
    "#     y_pred = nb_clf.predict(X_test)\n",
    "    \n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     accuracies.append(accuracy)\n",
    "\n",
    "# print(\"5-fold list of accuracies:\",accuracies)\n",
    "# print(f\"5-fold cross-validation mean accuracy: {np.mean(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export to tst.csv predictions for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tst.csv')\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(data.abstract)\n",
    "X = data.drop('id', axis=1)\n",
    "\n",
    "y_pred = nb_clf.predict(X['abstract'])\n",
    "\n",
    "df_predictions = pd.DataFrame({'id': range(1, len(y_pred) + 1), 'class': y_pred})\n",
    "df_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. explain and motivate the chosen representation & data preprocessing,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. explain the idea behind the model improvements and their implementation (including the implementation of the standard Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. explain the evaluation procedure (e.g., cross-validation or training/validation split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. include and explain the training/validation results for the standard and improved Naive Bayes model. You can summarize results using tables (or plots), but all results have to be explained descriptively as well. be written in plain English and should not be longer than two A4 pages (export the notebook as pdf to see if the report section fits in two pages)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
