{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sklearn for Windows devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install sklearn for MacOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1114.19s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "1120.58s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n",
      "Collecting nltk\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting click (from nltk)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Collecting regex>=2021.8.3 (from nltk)\n",
      "  Downloading regex-2024.4.28-cp312-cp312-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm (from nltk)\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0mm\n",
      "\u001b[?25hDownloading regex-2024.4.28-cp312-cp312-macosx_11_0_arm64.whl (278 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.5/278.5 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.8.1 regex-2024.4.28 tqdm-4.66.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install -U scikit-learn\n",
    "!pip3 install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0001</th>\n",
       "      <th>00017</th>\n",
       "      <th>0003</th>\n",
       "      <th>0004</th>\n",
       "      <th>0005</th>\n",
       "      <th>001</th>\n",
       "      <th>0021</th>\n",
       "      <th>003</th>\n",
       "      <th>...</th>\n",
       "      <th>zwf1</th>\n",
       "      <th>zwitterionic</th>\n",
       "      <th>zygomycete</th>\n",
       "      <th>zygomycetes</th>\n",
       "      <th>zygotic</th>\n",
       "      <th>zymogen</th>\n",
       "      <th>zymogens</th>\n",
       "      <th>zymogram</th>\n",
       "      <th>zymography</th>\n",
       "      <th>zymomonas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26179 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0001  00017  0003  0004  0005  001  0021  003  ...  zwf1  \\\n",
       "0   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "1   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "2   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "3   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "4   0    0     0      0     0     0     0    0     0    0  ...     0   \n",
       "\n",
       "   zwitterionic  zygomycete  zygomycetes  zygotic  zymogen  zymogens  \\\n",
       "0             0           0            0        0        0         0   \n",
       "1             0           0            0        0        0         0   \n",
       "2             0           0            0        0        0         0   \n",
       "3             0           0            0        0        0         0   \n",
       "4             0           0            0        0        0         0   \n",
       "\n",
       "   zymogram  zymography  zymomonas  \n",
       "0         0           0          0  \n",
       "1         0           0          0  \n",
       "2         0           0          0  \n",
       "3         0           0          0  \n",
       "4         0           0          0  \n",
       "\n",
       "[5 rows x 26179 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "data = pd.read_csv('trg.csv')\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(data.abstract)\n",
    "\n",
    "data = data.rename(columns={'class': 'class_label'})\n",
    "X = data.drop('class_label', axis=1)\n",
    "y = data['class_label']\n",
    "data  = pd.DataFrame(data= matrix.toarray(), columns = vectorizer.get_feature_names_out())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.93\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['abstract'], y, test_size=0.1, random_state=42)\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "        self.class_priors = {}\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.vocab = set()\n",
    "        for cls in self.classes:\n",
    "            self.class_counts[cls] = sum(1 for label in y if label == cls)\n",
    "        for abstract, label in zip(X, y):\n",
    "            for word in set(abstract.split()):\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        total_docs = len(X)\n",
    "        self.class_priors = {cls: self.class_counts[cls] / total_docs for cls in self.classes}\n",
    "\n",
    "    def predict(self, documents):\n",
    "        predictions = []\n",
    "        for document in documents:\n",
    "            posterior_probs = {cls: np.log(self.class_priors[cls]) for cls in self.classes}\n",
    "            document_words = document.split()\n",
    "            word_counts = {word: document_words.count(word) for word in set(document_words)}\n",
    "            for word, count in word_counts.items():\n",
    "                for cls in self.classes:\n",
    "                    word_count_in_class = self.word_counts[cls].get(word, 0)\n",
    "                    total_words_in_class = sum(self.word_counts[cls].values())\n",
    "                    conditional_prob = (word_count_in_class + 1) / (total_words_in_class + self.vocab_size)\n",
    "                    posterior_probs[cls] += count * np.log(conditional_prob)\n",
    "            predicted_class = max(posterior_probs, key=posterior_probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "        return predictions\n",
    "\n",
    "nb_clf = NaiveBayes()\n",
    "nb_clf.fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved with extra-preprocessing & Evaluating model's performance using k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X['abstract'], y, test_size=0.01, random_state=42)\n",
    "\n",
    "class NaiveBayes:\n",
    "    def __init__(self, alpha=1.0, use_bigrams=False, stemming=False):\n",
    "        self.word_counts = defaultdict(lambda: defaultdict(int))\n",
    "        self.class_counts = defaultdict(int)\n",
    "        self.vocab = set()\n",
    "        self.class_priors = {}\n",
    "        self.alpha = alpha\n",
    "        self.use_bigrams = use_bigrams\n",
    "        self.stemming = stemming\n",
    "        if self.stemming:\n",
    "            self.stemmer = PorterStemmer()\n",
    "            \n",
    "            \n",
    "    def get_params(self, deep=True):\n",
    "        return {\n",
    "            \"alpha\": self.alpha,\n",
    "            \"use_bigrams\": self.use_bigrams,\n",
    "            \"stemming\": self.stemming,\n",
    "        }\n",
    "\n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        words = text.split()\n",
    "        processed_words = []\n",
    "        skip_next = False\n",
    "        skip_next_next = False\n",
    "\n",
    "        for i, word in enumerate(words):\n",
    "            if skip_next:\n",
    "                skip_next = False\n",
    "                if skip_next_next:\n",
    "                    skip_next = True\n",
    "                    skip_next_next = False\n",
    "                continue\n",
    "\n",
    "            if word == \"homo\" and i + 1 < len(words) and words[i + 1] == \"sapiens\":\n",
    "                processed_words.append(\"homo-sapiens\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "\n",
    "            if word == \"escherichia\" and i + 1 < len(words) and words[i + 1] == \"coli\":\n",
    "                processed_words.append(\"escherichia-coli\")\n",
    "                skip_next = True\n",
    "                continue\n",
    "\n",
    "            if word == \"human\" and i + 2 < len(words) and words[i + 1] == \"immunodeficiency\" and words[i + 2] == \"virus\":\n",
    "                processed_words.append(\"human-immunodeficiency-virus\")\n",
    "                skip_next = True\n",
    "                skip_next_next = True\n",
    "                continue\n",
    "\n",
    "            if self.stemming:\n",
    "                word = self.stemmer.stem(word)\n",
    "\n",
    "            if word not in ENGLISH_STOP_WORDS:\n",
    "                processed_words.append(word)\n",
    "\n",
    "        if self.use_bigrams:\n",
    "            bigrams = [f\"{processed_words[i]}_{processed_words[i+1]}\" for i in range(len(processed_words)-1)]\n",
    "            processed_words.extend(bigrams)\n",
    "\n",
    "        return \" \".join(processed_words)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.vocab = set()\n",
    "\n",
    "        for cls in self.classes:\n",
    "            self.class_counts[cls] = sum(1 for label in y if label == cls)\n",
    "\n",
    "        for abstract, label in zip(X, y):\n",
    "            abstract = self.preprocess(abstract)\n",
    "            for word in set(abstract.split()):\n",
    "                self.word_counts[label][word] += 1\n",
    "                self.vocab.add(word)\n",
    "\n",
    "        self.vocab_size = len(self.vocab)\n",
    "        total_docs = len(X)\n",
    "        self.class_priors = {cls: self.class_counts[cls] / total_docs for cls in self.classes}\n",
    "\n",
    "    def predict(self, documents):\n",
    "        predictions = []\n",
    "        for document in documents:\n",
    "            document = self.preprocess(document)\n",
    "            posterior_probs = {cls: np.log(self.class_priors[cls]) for cls in self.classes}\n",
    "            document_words = document.split()\n",
    "            word_counts = {word: document_words.count(word) for word in set(document_words)}\n",
    "\n",
    "            for word, count in word_counts.items():\n",
    "                for cls in self.classes:\n",
    "                    word_count_in_class = self.word_counts[cls].get(word, 0)\n",
    "                    total_words_in_class = sum(self.word_counts[cls].values())\n",
    "                    conditional_prob = (word_count_in_class + self.alpha) / (total_words_in_class + self.alpha * self.vocab_size)\n",
    "                    posterior_probs[cls] += count * np.log(conditional_prob)\n",
    "\n",
    "            predicted_class = max(posterior_probs, key=posterior_probs.get)\n",
    "            predictions.append(predicted_class)\n",
    "\n",
    "        return predictions\n",
    "\n",
    "# kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "# accuracies = []\n",
    "\n",
    "nb_clf = NaiveBayes(alpha=0.5, use_bigrams=True, stemming=True)\n",
    "nb_clf.fit(X_train, y_train)\n",
    "y_pred = nb_clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# for train_index, test_index in kf.split(X['abstract']):\n",
    "#     X_train, X_test = X['abstract'][train_index], X['abstract'][test_index]\n",
    "#     y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "#     nb_clf.fit(X_train, y_train)\n",
    "#     y_pred = nb_clf.predict(X_test)\n",
    "    \n",
    "#     accuracy = accuracy_score(y_test, y_pred)\n",
    "#     accuracies.append(accuracy)\n",
    "\n",
    "# print(f\"5-fold cross-validation accuracy: {np.mean(accuracies):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export tst.csv predictions for kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('tst.csv')\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "matrix = vectorizer.fit_transform(data.abstract)\n",
    "X = data.drop('id', axis=1)\n",
    "\n",
    "y_pred = nb_clf.predict(X['abstract'])\n",
    "\n",
    "df_predictions = pd.DataFrame({'id': range(1, len(y_pred) + 1), 'class': y_pred})\n",
    "df_predictions.to_csv('predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Report Section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain and motivate the chosen representation & data preprocessing,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the idea behind the model improvements and their implementation (including the implementation of the standard Naive Bayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explain the evaluation procedure (e.g., cross-validation or training/validation split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include and explain the training/validation results for the standard and improved Naive Bayes model. You can summarize results using tables (or plots), but all results have to be explained descriptively as well. be written in plain English and should not be longer than two A4 pages (export the notebook as pdf to see if the report section fits in two pages)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
